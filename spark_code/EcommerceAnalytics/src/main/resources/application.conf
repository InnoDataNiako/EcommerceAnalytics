app {
  name = "EcommerceAnalytics"
  version = "1.0.0"

  data {
    input {
      transactions = "src/main/resources/data/transactions.csv"
      users = "src/main/resources/data/users.json"
      products = "src/main/resources/data/products.parquet"
      merchants = "src/main/resources/data/merchants.csv"
    }

    output {
      enriched = "output/enriched_data"
      merchant_report = "output/reports/merchant_report"
      cohort_analysis = "output/reports/cohort_analysis"
      top_products = "output/reports/top_products"
    }
  }

  spark {
    master = "local[*]"

    config {
      "spark.sql.warehouse.dir" = "file:///tmp/spark-warehouse"
      "spark.sql.legacy.allowUntypedScalaUDF" = "true"
      "spark.sql.adaptive.enabled" = "true"
      "spark.sql.adaptive.coalescePartitions.enabled" = "true"
      "spark.sql.adaptive.skewJoin.enabled" = "true"
      "spark.serializer" = "org.apache.spark.serializer.KryoSerializer"
      "spark.sql.shuffle.partitions" = "4"
      "spark.default.parallelism" = "4"
      "spark.executor.memory" = "2g"
      "spark.driver.memory" = "2g"
    }
  }

  # Niveau de log
  log.level = "ERROR"
}